"""
æ¼”ç¤ºä»£ç ï¼šLoRAé€‚é…å™¨çš„å¯ç»„åˆæ€§
æ–‡ä»¶ä½ç½®ï¼šcode/part2/04_lora_adapters_demo.py

å±•ç¤ºå¦‚ä½•ç”¨ä¸€ä¸ªåŸºåº§æ¨¡å‹ + å¤šä¸ªLoRAé€‚é…å™¨å®ç°å¤šä»»åŠ¡
"""

import numpy as np
from typing import Dict, List


class BaseModel:
    """åŸºåº§æ¨¡å‹ï¼ˆå†»ç»“ï¼‰"""
    
    def __init__(self, model_size: str = "7B"):
        self.model_size = model_size
        self.name = f"LLaMA-2-{model_size}"
        # æ¨¡æ‹Ÿå†»ç»“çš„æƒé‡
        self.frozen_weights = np.random.randn(100, 100) * 0.1
        print(f"âœ… åŠ è½½åŸºåº§æ¨¡å‹: {self.name}")
        print(f"   å‚æ•°é‡: {model_size}")
        print(f"   çŠ¶æ€: ğŸ”’ å®Œå…¨å†»ç»“")
    
    def forward(self, x: np.ndarray) -> np.ndarray:
        """åŸºåº§æ¨¡å‹çš„å‰å‘ä¼ æ’­"""
        return x @ self.frozen_weights


class LoRAAdapter:
    """LoRAé€‚é…å™¨"""
    
    def __init__(self, name: str, task: str, rank: int = 8):
        self.name = name
        self.task = task
        self.rank = rank
        
        # LoRAçŸ©é˜µ A å’Œ B
        self.lora_A = np.random.randn(100, rank) * 0.01
        self.lora_B = np.zeros((rank, 100))
        
        # è®¡ç®—å‚æ•°é‡
        self.params = 100 * rank * 2  # Aå’ŒBçš„å‚æ•°
        
        print(f"  ğŸ“¦ åˆ›å»ºé€‚é…å™¨: {name}")
        print(f"     ä»»åŠ¡: {task}")
        print(f"     å‚æ•°é‡: {self.params:,}")
    
    def forward(self, x: np.ndarray) -> np.ndarray:
        """LoRAé€‚é…å™¨çš„å‰å‘ä¼ æ’­"""
        return (x @ self.lora_A @ self.lora_B) * (16.0 / self.rank)  # scaling
    
    def get_storage_size(self) -> float:
        """è·å–å­˜å‚¨å¤§å°ï¼ˆMBï¼‰"""
        # FP16: 2 bytes per parameter
        return (self.params * 2) / (1024**2)


class MultiTaskModel:
    """æ”¯æŒå¤šä»»åŠ¡çš„æ¨¡å‹ï¼ˆä¸€ä¸ªåŸºåº§ + å¤šä¸ªLoRAï¼‰"""
    
    def __init__(self, base_model: BaseModel):
        self.base_model = base_model
        self.adapters: Dict[str, LoRAAdapter] = {}
        self.current_adapter = None
        
        print(f"\nğŸ¯ åˆ›å»ºå¤šä»»åŠ¡æ¨¡å‹ç³»ç»Ÿ")
        print(f"   åŸºåº§: {base_model.name}")
    
    def add_adapter(self, adapter: LoRAAdapter):
        """æ·»åŠ ä¸€ä¸ªLoRAé€‚é…å™¨"""
        self.adapters[adapter.name] = adapter
        print(f"âœ… å·²æ·»åŠ é€‚é…å™¨: {adapter.name} ({adapter.task})")
    
    def switch_adapter(self, adapter_name: str):
        """åˆ‡æ¢åˆ°æŒ‡å®šçš„é€‚é…å™¨"""
        if adapter_name in self.adapters:
            self.current_adapter = self.adapters[adapter_name]
            print(f"ğŸ”„ åˆ‡æ¢åˆ°é€‚é…å™¨: {adapter_name}")
        else:
            raise ValueError(f"æœªæ‰¾åˆ°é€‚é…å™¨: {adapter_name}")
    
    def forward(self, x: np.ndarray) -> np.ndarray:
        """å‰å‘ä¼ æ’­ï¼ˆåŸºåº§ + å½“å‰é€‚é…å™¨ï¼‰"""
        # åŸºåº§æ¨¡å‹è¾“å‡º
        base_output = self.base_model.forward(x)
        
        # å¦‚æœæœ‰æ´»è·ƒçš„é€‚é…å™¨ï¼ŒåŠ ä¸Šé€‚é…å™¨çš„è¾“å‡º
        if self.current_adapter:
            adapter_output = self.current_adapter.forward(x)
            return base_output + adapter_output
        
        return base_output
    
    def get_total_storage(self) -> float:
        """è®¡ç®—æ€»å­˜å‚¨éœ€æ±‚ï¼ˆGBï¼‰"""
        # åŸºåº§æ¨¡å‹ï¼ˆFP16ï¼‰
        base_size = (7_000_000_000 * 2) / (1024**3)  # 7Bæ¨¡å‹ç¤ºä¾‹
        
        # æ‰€æœ‰é€‚é…å™¨
        adapters_size = sum(adapter.get_storage_size() 
                          for adapter in self.adapters.values()) / 1024
        
        return base_size + adapters_size
    
    def print_summary(self):
        """æ‰“å°ç³»ç»Ÿæ‘˜è¦"""
        print(f"\n{'='*70}")
        print(f"ğŸ“Š å¤šä»»åŠ¡æ¨¡å‹ç³»ç»Ÿæ‘˜è¦")
        print(f"{'='*70}")
        
        print(f"\nğŸ§  åŸºåº§æ¨¡å‹:")
        print(f"   åç§°: {self.base_model.name}")
        print(f"   å¤§å°: ~13 GB (FP16)")
        print(f"   çŠ¶æ€: å†»ç»“ï¼ˆæ‰€æœ‰ä»»åŠ¡å…±äº«ï¼‰")
        
        print(f"\nğŸ”Œ LoRAé€‚é…å™¨åˆ—è¡¨:")
        total_adapter_size = 0
        for name, adapter in self.adapters.items():
            size_mb = adapter.get_storage_size()
            total_adapter_size += size_mb
            print(f"   â€¢ {name:<20} | {adapter.task:<30} | {size_mb:.2f} MB")
        
        print(f"\nğŸ’¾ å­˜å‚¨éœ€æ±‚:")
        print(f"   åŸºåº§æ¨¡å‹: ~13 GB")
        print(f"   æ‰€æœ‰é€‚é…å™¨: {total_adapter_size:.2f} MB")
        print(f"   æ€»è®¡: ~{13 + total_adapter_size/1024:.2f} GB")
        
        print(f"\nğŸ’¡ å­˜å‚¨ä¼˜åŠ¿:")
        # å¦‚æœç”¨å…¨é‡å¾®è°ƒ
        full_ft_storage = 13 * len(self.adapters)
        print(f"   å…¨é‡å¾®è°ƒéœ€è¦: {full_ft_storage} GB ({len(self.adapters)}ä¸ªä»»åŠ¡ Ã— 13GB)")
        print(f"   LoRAæ–¹æ¡ˆéœ€è¦: ~{13 + total_adapter_size/1024:.2f} GB")
        savings = full_ft_storage - (13 + total_adapter_size/1024)
        print(f"   èŠ‚çœç©ºé—´: {savings:.1f} GB ({savings/full_ft_storage*100:.1f}%)")


def demonstrate_hub_and_spoke():
    """æ¼”ç¤ºHub-and-Spokeæ¶æ„"""
    
    print("="*70)
    print("ğŸ¯ æ¼”ç¤ºï¼šHub-and-Spoke å¤šä»»åŠ¡æ¶æ„")
    print("="*70)
    
    # 1. åˆ›å»ºåŸºåº§æ¨¡å‹ï¼ˆHub - ä¸­å¿ƒï¼‰
    print("\næ­¥éª¤1: åŠ è½½åŸºåº§æ¨¡å‹")
    print("-"*70)
    base_model = BaseModel("7B")
    
    # 2. åˆ›å»ºå¤šä»»åŠ¡ç³»ç»Ÿ
    print("\næ­¥éª¤2: åˆ›å»ºå¤šä»»åŠ¡ç³»ç»Ÿ")
    print("-"*70)
    multi_task_model = MultiTaskModel(base_model)
    
    # 3. åˆ›å»ºå¤šä¸ªLoRAé€‚é…å™¨ï¼ˆSpokes - è¾æ¡ï¼‰
    print("\næ­¥éª¤3: åˆ›å»ºä¸“ç”¨LoRAé€‚é…å™¨")
    print("-"*70)
    
    adapters = [
        LoRAAdapter("email_summary", "é‚®ä»¶æ€»ç»“", rank=8),
        LoRAAdapter("code_generation", "Pythonä»£ç ç”Ÿæˆ", rank=16),
        LoRAAdapter("sql_query", "SQLæŸ¥è¯¢ç”Ÿæˆ", rank=8),
        LoRAAdapter("creative_writing", "åˆ›æ„å†™ä½œ", rank=16),
        LoRAAdapter("customer_service", "å®¢æˆ·æœåŠ¡å¯¹è¯", rank=8),
        LoRAAdapter("translation_cn_en", "ä¸­è‹±ç¿»è¯‘", rank=8),
    ]
    
    # 4. æ·»åŠ æ‰€æœ‰é€‚é…å™¨
    print("\næ­¥éª¤4: å°†é€‚é…å™¨åŠ è½½åˆ°ç³»ç»Ÿ")
    print("-"*70)
    for adapter in adapters:
        multi_task_model.add_adapter(adapter)
    
    # 5. æ¼”ç¤ºä»»åŠ¡åˆ‡æ¢
    print("\næ­¥éª¤5: æ¼”ç¤ºå¿«é€Ÿä»»åŠ¡åˆ‡æ¢")
    print("-"*70)
    
    test_input = np.random.randn(1, 100)
    
    tasks = ["email_summary", "code_generation", "customer_service"]
    for task_name in tasks:
        multi_task_model.switch_adapter(task_name)
        output = multi_task_model.forward(test_input)
        print(f"   æ‰§è¡Œä»»åŠ¡å®Œæˆ: {task_name}")
    
    # 6. æ‰“å°æ‘˜è¦
    multi_task_model.print_summary()
    
    # 7. å¯¹æ¯”
    print(f"\n{'='*70}")
    print("ğŸ” æ–¹æ¡ˆå¯¹æ¯”")
    print(f"{'='*70}")
    
    print(f"\nã€ä¼ ç»Ÿæ–¹æ¡ˆï¼šæ¯ä¸ªä»»åŠ¡ä¸€ä¸ªå®Œæ•´æ¨¡å‹ã€‘")
    print(f"  éœ€è¦è®­ç»ƒ: {len(adapters)}ä¸ªå®Œæ•´æ¨¡å‹")
    print(f"  æ€»å­˜å‚¨: {len(adapters) * 13} GB")
    print(f"  åˆ‡æ¢ä»»åŠ¡: éœ€è¦é‡æ–°åŠ è½½æ•´ä¸ªæ¨¡å‹ï¼ˆæ…¢ï¼‰")
    print(f"  ç»´æŠ¤æˆæœ¬: é«˜ï¼ˆç®¡ç†{len(adapters)}ä¸ªå¤§æ¨¡å‹ï¼‰")
    
    print(f"\nã€LoRAæ–¹æ¡ˆï¼šä¸€ä¸ªåŸºåº§ + å¤šä¸ªé€‚é…å™¨ã€‘")
    print(f"  éœ€è¦è®­ç»ƒ: 1ä¸ªåŸºåº§ + {len(adapters)}ä¸ªè½»é‡é€‚é…å™¨")
    total_size = 13 + sum(a.get_storage_size() for a in adapters) / 1024
    print(f"  æ€»å­˜å‚¨: {total_size:.2f} GB")
    print(f"  åˆ‡æ¢ä»»åŠ¡: ä»…éœ€åŠ è½½é€‚é…å™¨ï¼ˆå¿«ï¼Œå‡ MBï¼‰")
    print(f"  ç»´æŠ¤æˆæœ¬: ä½ï¼ˆç®¡ç†1ä¸ªåŸºåº§ + {len(adapters)}ä¸ªå°æ–‡ä»¶ï¼‰")
    
    print(f"\nğŸ’¡ å…³é”®ä¼˜åŠ¿:")
    print(f"  âœ“ å­˜å‚¨èŠ‚çœ: {len(adapters) * 13 - total_size:.1f} GB")
    print(f"  âœ“ çµæ´»ç»„åˆ: å¯ä»¥åŠ¨æ€åŠ è½½/å¸è½½é€‚é…å™¨")
    print(f"  âœ“ å¿«é€Ÿè¿­ä»£: æ–°ä»»åŠ¡åªéœ€è®­ç»ƒä¸€ä¸ªå°é€‚é…å™¨")
    print(f"  âœ“ æ˜“äºéƒ¨ç½²: åŸºåº§æ¨¡å‹ä¸€æ¬¡åŠ è½½ï¼Œé€‚é…å™¨æŒ‰éœ€åˆ‡æ¢")
    
    print("\nğŸ“ ä»£ç ä½ç½®: code/part2/04_lora_adapters_demo.py")


if __name__ == "__main__":
    demonstrate_hub_and_spoke()

