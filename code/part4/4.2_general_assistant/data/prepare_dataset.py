"""
4.2 é€šç”¨å¯¹è¯åŠ©æ‰‹ - æ•°æ®é¢„å¤„ç†
å°†å¤šä»»åŠ¡æ•°æ®è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
"""

import json
import os
from typing import List, Dict
from datasets import Dataset
import pandas as pd


class GeneralAssistantDatasetPreparer:
    """é€šç”¨åŠ©æ‰‹æ•°æ®é›†å‡†å¤‡å™¨"""
    
    def __init__(self, raw_data_path: str = 'general_assistant_raw_data.json'):
        self.raw_data_path = raw_data_path
        
    def load_raw_data(self) -> List[Dict]:
        """åŠ è½½åŸå§‹æ•°æ®"""
        with open(self.raw_data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"âœ… åŠ è½½äº† {len(data)} æ¡åŸå§‹æ•°æ®")
        return data
    
    def format_for_training(self, data: List[Dict]) -> List[Dict]:
        """æ ¼å¼åŒ–æ•°æ®ä¸ºè®­ç»ƒæ ¼å¼"""
        formatted_data = []
        
        for item in data:
            formatted_item = {
                'instruction': item['instruction'],
                'input': item['input'],
                'output': item['output'],
                'task_type': item.get('task_type', 'general'),
                'text': self._create_full_prompt(item)
            }
            formatted_data.append(formatted_item)
        
        print(f"âœ… æ ¼å¼åŒ–äº† {len(formatted_data)} æ¡æ•°æ®")
        return formatted_data
    
    def _create_full_prompt(self, item: Dict) -> str:
        """åˆ›å»ºå®Œæ•´çš„è®­ç»ƒæ–‡æœ¬"""
        instruction = item['instruction']
        input_text = item['input']
        output = item['output']
        
        prompt = f"""<s>[INST] <<SYS>>
{instruction}
<</SYS>>

{input_text} [/INST] {output} </s>"""
        
        return prompt
    
    def split_dataset(self, data: List[Dict], train_ratio: float = 0.9) -> tuple:
        """åˆ’åˆ†æ•°æ®é›†ï¼Œä¿æŒä»»åŠ¡ç±»å‹å¹³è¡¡"""
        import random
        random.seed(42)
        
        # æŒ‰ä»»åŠ¡ç±»å‹åˆ†ç»„
        task_groups = {}
        for item in data:
            task = item.get('task_type', 'general')
            if task not in task_groups:
                task_groups[task] = []
            task_groups[task].append(item)
        
        # æ¯ä¸ªä»»åŠ¡ç±»å‹åˆ†åˆ«åˆ’åˆ†
        train_data = []
        val_data = []
        
        for task, items in task_groups.items():
            random.shuffle(items)
            split_idx = int(len(items) * train_ratio)
            train_data.extend(items[:split_idx])
            val_data.extend(items[split_idx:])
        
        # æ‰“ä¹±é¡ºåº
        random.shuffle(train_data)
        random.shuffle(val_data)
        
        print(f"ğŸ“Š æ•°æ®åˆ’åˆ†:")
        print(f"  è®­ç»ƒé›†: {len(train_data)} æ¡")
        print(f"  éªŒè¯é›†: {len(val_data)} æ¡")
        
        return train_data, val_data
    
    def save_to_json(self, data: List[Dict], output_path: str):
        """ä¿å­˜ä¸ºJSONæ ¼å¼"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"âœ… ä¿å­˜åˆ°: {output_path}")
    
    def save_to_huggingface_format(self, train_data: List[Dict], 
                                   val_data: List[Dict],
                                   output_dir: str = 'processed'):
        """ä¿å­˜ä¸ºHuggingFaceæ ¼å¼"""
        os.makedirs(output_dir, exist_ok=True)
        
        train_dataset = Dataset.from_pandas(pd.DataFrame(train_data))
        val_dataset = Dataset.from_pandas(pd.DataFrame(val_data))
        
        train_dataset.save_to_disk(f"{output_dir}/train")
        val_dataset.save_to_disk(f"{output_dir}/val")
        
        print(f"âœ… HuggingFaceæ ¼å¼æ•°æ®ä¿å­˜åˆ°: {output_dir}/")
    
    def prepare_full_pipeline(self):
        """å®Œæ•´çš„æ•°æ®å‡†å¤‡æµç¨‹"""
        print("="*80)
        print("ğŸš€ å¼€å§‹æ•°æ®å‡†å¤‡æµç¨‹")
        print("="*80)
        
        raw_data = self.load_raw_data()
        formatted_data = self.format_for_training(raw_data)
        train_data, val_data = self.split_dataset(formatted_data)
        
        print("\nğŸ’¾ ä¿å­˜æ•°æ®...")
        self.save_to_json(train_data, 'train_data.json')
        self.save_to_json(val_data, 'val_data.json')
        self.save_to_huggingface_format(train_data, val_data)
        
        print("\nâœ… æ•°æ®å‡†å¤‡å®Œæˆï¼")
        return train_data, val_data


if __name__ == "__main__":
    preparer = GeneralAssistantDatasetPreparer()
    preparer.prepare_full_pipeline()

