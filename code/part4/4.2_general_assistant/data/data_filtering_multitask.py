"""
4.2 é€šç”¨å¯¹è¯åŠ©æ‰‹ - å¤šä»»åŠ¡æ•°æ®ç­›é€‰ä¸å¹³è¡¡
å±•ç¤ºå¤šä»»åŠ¡SFTçš„çœŸå®æ•°æ®å‡†å¤‡è¿‡ç¨‹
"""

import json
import re
from typing import List, Dict
from collections import Counter
import random


class MultiTaskDataFilteringPipeline:
    """
    å¤šä»»åŠ¡æ•°æ®ç­›é€‰æµæ°´çº¿
    å¤„ç†10+ç§ä»»åŠ¡ç±»å‹çš„æ•°æ®å¹³è¡¡å’Œè´¨é‡æ§åˆ¶
    """
    
    def __init__(self, raw_data_path: str):
        self.raw_data_path = raw_data_path
        self.raw_data = self.load_data(raw_data_path)
        self.filtering_history = []
        
    def load_data(self, path: str) -> List[Dict]:
        """åŠ è½½åŸå§‹æ•°æ®"""
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def run_full_pipeline(self):
        """è¿è¡Œå®Œæ•´çš„ç­›é€‰æµç¨‹"""
        print("="*80)
        print("ğŸ” å¤šä»»åŠ¡æ•°æ®ç­›é€‰æµæ°´çº¿ - çœŸå®åœºæ™¯")
        print("="*80)
        
        # ç¬¬ä¸€è½®ï¼šä»»åŠ¡åˆ†ç±»å’Œç»Ÿè®¡
        round1_data = self.round1_task_classification(self.raw_data)
        
        # å‘ç°é—®é¢˜ï¼šä»»åŠ¡åˆ†å¸ƒä¸¥é‡ä¸å‡è¡¡
        self.discover_task_imbalance_problem(round1_data)
        
        # ç¬¬äºŒè½®ï¼šä»»åŠ¡å¹³è¡¡ç­–ç•¥
        round2_data = self.round2_task_balancing(round1_data)
        
        # ç¬¬ä¸‰è½®ï¼šè´¨é‡ç­›é€‰
        round3_data = self.round3_quality_filtering(round2_data)
        
        # å‘ç°æ–°é—®é¢˜ï¼šä»»åŠ¡å†²çª
        self.discover_task_conflict_problem(round3_data)
        
        # ç¬¬å››è½®ï¼šè§£å†³ä»»åŠ¡å†²çª
        round4_data = self.round4_resolve_conflicts(round3_data)
        
        # ç¬¬äº”è½®ï¼šæœ€ç»ˆéªŒè¯
        final_data = self.round5_final_validation(round4_data)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
        
        return final_data
    
    def round1_task_classification(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬ä¸€è½®ï¼šä»»åŠ¡åˆ†ç±»å’Œç»Ÿè®¡
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬ä¸€è½®ï¼šä»»åŠ¡åˆ†ç±»å’Œç»Ÿè®¡")
        print("="*80)
        
        # ç»Ÿè®¡æ¯ä¸ªä»»åŠ¡ç±»å‹çš„æ•°é‡
        task_distribution = Counter()
        for item in data:
            task_type = item.get('task_type', 'unknown')
            task_distribution[task_type] += 1
        
        print(f"\nğŸ“Š ä»»åŠ¡åˆ†å¸ƒç»Ÿè®¡:")
        print(f"  æ€»æ•°æ®é‡: {len(data)}")
        print(f"  ä»»åŠ¡ç±»å‹æ•°: {len(task_distribution)}")
        print(f"\nå„ä»»åŠ¡æ•°é‡:")
        
        for task, count in task_distribution.most_common():
            percentage = count / len(data) * 100
            bar = 'â–ˆ' * int(percentage / 2)
            print(f"  {task:20s}: {count:3d} ({percentage:5.1f}%) {bar}")
        
        self.filtering_history.append({
            'round': 1,
            'name': 'ä»»åŠ¡åˆ†ç±»ç»Ÿè®¡',
            'task_distribution': dict(task_distribution)
        })
        
        return data
    
    def discover_task_imbalance_problem(self, data: List[Dict]):
        """
        å‘ç°é—®é¢˜ï¼šä»»åŠ¡åˆ†å¸ƒä¸¥é‡ä¸å‡è¡¡
        """
        print("\n" + "!"*80)
        print("âŒ é—®é¢˜å‘ç°ï¼šä»»åŠ¡åˆ†å¸ƒä¸¥é‡ä¸å‡è¡¡ï¼")
        print("!"*80)
        
        task_counts = Counter(item.get('task_type') for item in data)
        max_count = max(task_counts.values())
        min_count = min(task_counts.values())
        
        problems = [
            {
                'problem': 'æ•°æ®åˆ†å¸ƒæåº¦ä¸å‡',
                'detail': f'æœ€å¤šçš„ä»»åŠ¡({max_count}æ¡) vs æœ€å°‘çš„ä»»åŠ¡({min_count}æ¡)ï¼Œç›¸å·®{max_count/min_count:.1f}å€ï¼',
                'impact': 'æ¨¡å‹ä¼šä¸¥é‡åå‘é«˜é¢‘ä»»åŠ¡ï¼Œä½é¢‘ä»»åŠ¡åŸºæœ¬å­¦ä¸ä¼š',
                'example': 'æ¯”å¦‚ä»£ç ç”Ÿæˆæœ‰500æ¡ï¼Œä½†ç¿»è¯‘åªæœ‰50æ¡'
            },
            {
                'problem': 'æŸäº›ä»»åŠ¡æ•°æ®è´¨é‡å·®',
                'detail': 'ä½é¢‘ä»»åŠ¡çš„æ•°æ®å¾€å¾€æ˜¯ä¸´æ—¶è¡¥å……çš„ï¼Œè´¨é‡ä¸å¦‚é«˜é¢‘ä»»åŠ¡',
                'impact': 'å³ä½¿å¹³è¡¡äº†æ•°é‡ï¼Œæ¨¡å‹åœ¨ä½é¢‘ä»»åŠ¡ä¸Šè¡¨ç°ä»ç„¶å·®',
                'example': 'ä»£ç ä»»åŠ¡æ˜¯ä¸“å®¶å†™çš„ï¼Œç¿»è¯‘ä»»åŠ¡æ˜¯AIç”Ÿæˆçš„'
            },
            {
                'problem': 'ä»»åŠ¡éš¾åº¦ä¸ä¸€è‡´',
                'detail': 'ç®€å•ä»»åŠ¡ï¼ˆå¦‚æ‘˜è¦ï¼‰å’Œå¤æ‚ä»»åŠ¡ï¼ˆå¦‚æ¨ç†ï¼‰æ··åœ¨ä¸€èµ·',
                'impact': 'æ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆç®€å•ä»»åŠ¡ï¼Œå¤æ‚ä»»åŠ¡å­¦ä¸å¥½',
                'example': 'æ‘˜è¦åªéœ€è¦æå–å…³é”®è¯ï¼Œæ¨ç†éœ€è¦å¤šæ­¥æ€è€ƒ'
            }
        ]
        
        for i, prob in enumerate(problems, 1):
            print(f"\né—®é¢˜ {i}: {prob['problem']}")
            print(f"  è¯¦æƒ…: {prob['detail']}")
            print(f"  å½±å“: {prob['impact']}")
            print(f"  ä¸¾ä¾‹: {prob['example']}")
        
        print("\nğŸ’¡ å…³é”®æ•™è®­ï¼š")
        print("   å¤šä»»åŠ¡SFTæœ€å¤§çš„æŒ‘æˆ˜å°±æ˜¯ä»»åŠ¡å¹³è¡¡ï¼")
        print("   ä¸ä»…è¦å¹³è¡¡æ•°é‡ï¼Œè¿˜è¦å¹³è¡¡è´¨é‡ã€éš¾åº¦ã€é‡è¦æ€§")
    
    def round2_task_balancing(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬äºŒè½®ï¼šä»»åŠ¡å¹³è¡¡ç­–ç•¥
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬äºŒè½®ï¼šä»»åŠ¡å¹³è¡¡")
        print("="*80)
        
        # ç»Ÿè®¡å½“å‰åˆ†å¸ƒ
        task_groups = {}
        for item in data:
            task = item.get('task_type', 'unknown')
            if task not in task_groups:
                task_groups[task] = []
            task_groups[task].append(item)
        
        print(f"\nå¹³è¡¡ç­–ç•¥ï¼š")
        print(f"  ç›®æ ‡: æ¯ä¸ªä»»åŠ¡è‡³å°‘100æ¡ï¼Œæœ€å¤š200æ¡")
        print(f"  æ–¹æ³•: ä¸Šé‡‡æ ·ï¼ˆå¤åˆ¶ï¼‰+ ä¸‹é‡‡æ ·ï¼ˆåˆ é™¤ï¼‰")
        
        balanced_data = []
        target_min = 100
        target_max = 200
        
        for task, items in task_groups.items():
            count = len(items)
            
            if count < target_min:
                # ä¸Šé‡‡æ ·ï¼šé‡å¤æ•°æ®
                repeat_times = target_min // count + 1
                sampled = (items * repeat_times)[:target_min]
                action = f"ä¸Šé‡‡æ · {count}â†’{len(sampled)}"
            elif count > target_max:
                # ä¸‹é‡‡æ ·ï¼šéšæœºé€‰æ‹©
                sampled = random.sample(items, target_max)
                action = f"ä¸‹é‡‡æ · {count}â†’{len(sampled)}"
            else:
                sampled = items
                action = f"ä¿æŒ {count}"
            
            balanced_data.extend(sampled)
            print(f"  {task:20s}: {action}")
        
        print(f"\nå¹³è¡¡åæ€»æ•°: {len(balanced_data)}")
        
        self.filtering_history.append({
            'round': 2,
            'name': 'ä»»åŠ¡å¹³è¡¡',
            'before': len(data),
            'after': len(balanced_data),
            'strategy': 'up/down sampling'
        })
        
        return balanced_data
    
    def round3_quality_filtering(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬ä¸‰è½®ï¼šè´¨é‡ç­›é€‰
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬ä¸‰è½®ï¼šè´¨é‡ç­›é€‰")
        print("="*80)
        
        filtered = []
        quality_scores = []
        
        for item in data:
            score = self._evaluate_quality(item)
            item['quality_score'] = score
            quality_scores.append(score)
            
            # é˜ˆå€¼ï¼š7.0åˆ†ä»¥ä¸Š
            if score >= 7.0:
                filtered.append(item)
        
        avg_score = sum(quality_scores) / len(quality_scores)
        
        print(f"\nè´¨é‡è¯„ä¼°:")
        print(f"  å¹³å‡åˆ†: {avg_score:.2f}/10")
        print(f"  é€šè¿‡ç‡: {len(filtered)}/{len(data)} ({len(filtered)/len(data)*100:.1f}%)")
        print(f"  æ‹’ç»: {len(data) - len(filtered)} æ¡ä½è´¨é‡æ•°æ®")
        
        self.filtering_history.append({
            'round': 3,
            'name': 'è´¨é‡ç­›é€‰',
            'threshold': 7.0,
            'pass_rate': len(filtered)/len(data)
        })
        
        return filtered
    
    def _evaluate_quality(self, item: Dict) -> float:
        """è¯„ä¼°æ•°æ®è´¨é‡"""
        score = 10.0
        
        # é•¿åº¦æ£€æŸ¥
        input_len = len(item.get('input', ''))
        output_len = len(item.get('output', ''))
        
        if input_len < 10:
            score -= 2.0
        if output_len < 50:
            score -= 2.0
        
        # å®Œæ•´æ€§æ£€æŸ¥
        if not item.get('instruction'):
            score -= 1.0
        
        # ä»»åŠ¡ç‰¹å®šæ£€æŸ¥
        task = item.get('task_type')
        if task == 'code_generation':
            if 'def ' not in item.get('output', '') and 'class ' not in item.get('output', ''):
                score -= 1.5
        elif task == 'math_reasoning':
            if '=' not in item.get('output', ''):
                score -= 1.0
        
        return max(0, min(10, score))
    
    def discover_task_conflict_problem(self, data: List[Dict]):
        """
        å‘ç°æ–°é—®é¢˜ï¼šä»»åŠ¡å†²çª
        """
        print("\n" + "!"*80)
        print("âŒ æ–°é—®é¢˜ï¼šä»»åŠ¡ä¹‹é—´å­˜åœ¨å†²çªï¼")
        print("!"*80)
        
        conflicts = [
            {
                'conflict': 'ä»£ç ç”Ÿæˆ vs åˆ›æ„å†™ä½œ',
                'description': 'ä»£ç è¦æ±‚ä¸¥æ ¼æ ¼å¼ï¼Œå†™ä½œè¦æ±‚åˆ›é€ æ€§',
                'manifestation': 'æ¨¡å‹åœ¨å†™ä½œæ—¶ä¹Ÿæƒ³è¾“å‡ºä»£ç å—ï¼Œæˆ–è€…ä»£ç ç¼ºå°‘æ³¨é‡Š',
                'impact': 'ä¸¤ç§ä»»åŠ¡ç›¸äº’å¹²æ‰°ï¼Œéƒ½å­¦ä¸å¥½'
            },
            {
                'conflict': 'é—®ç­” vs å¤´è„‘é£æš´',
                'description': 'é—®ç­”è¦æ±‚å‡†ç¡®å”¯ä¸€ç­”æ¡ˆï¼Œå¤´è„‘é£æš´è¦æ±‚å¤šä¸ªé€‰é¡¹',
                'manifestation': 'é—®ç­”æ—¶ç»™å‡ºå¤šä¸ªç­”æ¡ˆï¼ˆä¸ç¡®å®šï¼‰ï¼Œå¤´è„‘é£æš´åªç»™ä¸€ä¸ªï¼ˆå¤ªå•ä¸€ï¼‰',
                'impact': 'æ¨¡å‹åœ¨ä¸åŒä»»åŠ¡é—´äº§ç”Ÿæ··æ·†'
            },
            {
                'conflict': 'ç¿»è¯‘ vs æ‘˜è¦',
                'description': 'ç¿»è¯‘è¦æ±‚å®Œæ•´ä¿ç•™ä¿¡æ¯ï¼Œæ‘˜è¦è¦æ±‚å‹ç¼©ä¿¡æ¯',
                'manifestation': 'ç¿»è¯‘æ—¶ä¸¢å¤±ç»†èŠ‚ï¼Œæ‘˜è¦æ—¶è¿‡äºè¯¦ç»†',
                'impact': 'æ¨¡å‹ä¸æ¸…æ¥šä½•æ—¶ä¿ç•™ã€ä½•æ—¶åˆ å‡'
            }
        ]
        
        for i, conflict in enumerate(conflicts, 1):
            print(f"\nå†²çª {i}: {conflict['conflict']}")
            print(f"  æè¿°: {conflict['description']}")
            print(f"  è¡¨ç°: {conflict['manifestation']}")
            print(f"  å½±å“: {conflict['impact']}")
        
        print("\nğŸ’¡ æ ¹æœ¬åŸå› ï¼š")
        print("   ä¸åŒä»»åŠ¡å¯¹æ¨¡å‹è¡Œä¸ºçš„è¦æ±‚æ˜¯çŸ›ç›¾çš„")
        print("   åœ¨å°æ•°æ®é›†ä¸Šï¼Œæ¨¡å‹éš¾ä»¥åŒºåˆ†ä¸åŒä»»åŠ¡çš„ä¸Šä¸‹æ–‡")
    
    def round4_resolve_conflicts(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬å››è½®ï¼šè§£å†³ä»»åŠ¡å†²çª
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬å››è½®ï¼šè§£å†³ä»»åŠ¡å†²çª")
        print("="*80)
        
        print(f"\nè§£å†³æ–¹æ¡ˆ:")
        
        # æ–¹æ¡ˆ1ï¼šå¼ºåŒ–ä»»åŠ¡æç¤º
        print(f"\n1. å¼ºåŒ–ä»»åŠ¡æç¤ºï¼ˆåœ¨instructionä¸­æ˜ç¡®è¯´æ˜ï¼‰")
        for item in data:
            task = item.get('task_type')
            if task == 'code_generation':
                item['instruction'] = 'è¯·ç¼–å†™ä»£ç å®ç°ä»¥ä¸‹åŠŸèƒ½ã€‚è¦æ±‚ï¼šä»£ç è§„èŒƒã€æœ‰æ³¨é‡Šã€å¯è¿è¡Œã€‚'
            elif task == 'creative_writing':
                item['instruction'] = 'è¯·å‘æŒ¥åˆ›é€ åŠ›ï¼Œç»­å†™æ•…äº‹ã€‚è¦æ±‚ï¼šå¼•äººå…¥èƒœã€æƒ…èŠ‚åˆç†ã€‚'
            elif task == 'qa':
                item['instruction'] = 'è¯·å‡†ç¡®å›ç­”é—®é¢˜ã€‚è¦æ±‚ï¼šç­”æ¡ˆå”¯ä¸€ã€æœ‰ä¾æ®ã€‚'
            elif task == 'brainstorming':
                item['instruction'] = 'è¯·æä¾›å¤šä¸ªåˆ›æ„æ–¹æ¡ˆã€‚è¦æ±‚ï¼šè‡³å°‘5ä¸ªã€å¤šæ ·åŒ–ã€‚'
        
        # æ–¹æ¡ˆ2ï¼šæ·»åŠ ä»»åŠ¡æ ‡ç­¾
        print(f"\n2. æ·»åŠ æ˜ç¡®çš„ä»»åŠ¡ç±»å‹æ ‡ç­¾")
        for item in data:
            task = item.get('task_type', 'general')
            item['instruction'] = f"[ä»»åŠ¡ç±»å‹: {task}] " + item.get('instruction', '')
        
        # æ–¹æ¡ˆ3ï¼šåˆ†ç»„è®­ç»ƒï¼ˆæ¨¡æ‹Ÿï¼‰
        print(f"\n3. åˆ†ç»„è®­ç»ƒç­–ç•¥ï¼ˆè®­ç»ƒæ—¶ä½¿ç”¨ï¼‰")
        print(f"   - ç¬¬1-2 epoch: æ‰€æœ‰ä»»åŠ¡æ··åˆ")
        print(f"   - ç¬¬3 epoch: æŒ‰ä»»åŠ¡ç±»å‹åˆ†æ‰¹è®­ç»ƒ")
        print(f"   - è¿™æ ·æ¨¡å‹æ—¢èƒ½å­¦ä¼šé€šç”¨èƒ½åŠ›ï¼Œåˆèƒ½åŒºåˆ†ä»»åŠ¡")
        
        self.filtering_history.append({
            'round': 4,
            'name': 'è§£å†³ä»»åŠ¡å†²çª',
            'solutions': ['å¼ºåŒ–æç¤º', 'ä»»åŠ¡æ ‡ç­¾', 'åˆ†ç»„è®­ç»ƒ']
        })
        
        return data
    
    def round5_final_validation(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬äº”è½®ï¼šæœ€ç»ˆéªŒè¯
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬äº”è½®ï¼šæœ€ç»ˆéªŒè¯")
        print("="*80)
        
        # éªŒè¯ä»»åŠ¡åˆ†å¸ƒ
        task_counts = Counter(item.get('task_type') for item in data)
        print(f"\næœ€ç»ˆä»»åŠ¡åˆ†å¸ƒ:")
        for task, count in task_counts.most_common():
            print(f"  {task:20s}: {count} æ¡")
        
        # éªŒè¯è´¨é‡åˆ†å¸ƒ
        quality_scores = [item.get('quality_score', 0) for item in data]
        avg_quality = sum(quality_scores) / len(quality_scores)
        print(f"\nå¹³å‡è´¨é‡: {avg_quality:.2f}/10")
        
        # éªŒè¯å®Œæ•´æ€§
        complete_count = sum(1 for item in data 
                           if item.get('instruction') and 
                              item.get('input') and 
                              item.get('output'))
        print(f"å®Œæ•´æ€§: {complete_count}/{len(data)} ({complete_count/len(data)*100:.1f}%)")
        
        # ä¿å­˜æœ€ç»ˆæ•°æ®
        output_path = 'multitask_filtered_final.json'
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… æœ€ç»ˆæ•°æ®å·²ä¿å­˜: {output_path}")
        
        self.filtering_history.append({
            'round': 5,
            'name': 'æœ€ç»ˆéªŒè¯',
            'total': len(data),
            'avg_quality': avg_quality
        })
        
        return data
    
    def generate_report(self):
        """ç”Ÿæˆç­›é€‰æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š å¤šä»»åŠ¡æ•°æ®ç­›é€‰å®Œæ•´æŠ¥å‘Š")
        print("="*80)
        
        for record in self.filtering_history:
            print(f"\nç¬¬{record['round']}è½®: {record['name']}")
            for key, value in record.items():
                if key not in ['round', 'name']:
                    print(f"  {key}: {value}")
        
        print("\nğŸ’¡ å¤šä»»åŠ¡SFTçš„å…³é”®ç»éªŒ:")
        print("  1. ä»»åŠ¡å¹³è¡¡æ˜¯ç¬¬ä¸€è¦åŠ¡")
        print("  2. è´¨é‡æ¯”æ•°é‡é‡è¦ï¼Œä½†ä¹Ÿè¦ä¿è¯æ¯ä¸ªä»»åŠ¡çš„æœ€å°é‡")
        print("  3. ä»»åŠ¡å†²çªéœ€è¦é€šè¿‡æç¤ºå·¥ç¨‹å’Œè®­ç»ƒç­–ç•¥è§£å†³")
        print("  4. æŒç»­ç›‘æ§å„ä»»åŠ¡çš„è¡¨ç°ï¼ŒåŠæ—¶è°ƒæ•´")


def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ¯ å¤šä»»åŠ¡SFTæ•°æ®ç­›é€‰ - çœŸå®åœºæ™¯æ¼”ç¤º")
    print("="*80)
    print("\nè¿™å±•ç¤ºäº†å¤šä»»åŠ¡å­¦ä¹ çš„ç‰¹æ®ŠæŒ‘æˆ˜ï¼š")
    print("  - ä»»åŠ¡åˆ†å¸ƒä¸å‡è¡¡")
    print("  - ä»»åŠ¡ä¹‹é—´å­˜åœ¨å†²çª")
    print("  - éœ€è¦ç‰¹æ®Šçš„å¹³è¡¡ç­–ç•¥")
    print("\n" + "="*80)
    input("\næŒ‰Enteré”®å¼€å§‹...")
    
    pipeline = MultiTaskDataFilteringPipeline('general_assistant_raw_data.json')
    final_data = pipeline.run_full_pipeline()
    
    print("\n" + "="*80)
    print("âœ… ç­›é€‰æµç¨‹å®Œæˆï¼")
    print("="*80)


if __name__ == "__main__":
    main()

