import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import os

# ==============================================================================
# 1. æ ¸å¿ƒ Trainer ç±»
# ==============================================================================
class Trainer:
    """
    ä¸€ä¸ªé€šç”¨çš„æ¨¡å‹è®­ç»ƒå™¨ã€‚
    """
    def __init__(self, model, train_loader, val_loader, criterion, optimizer, device, epochs, save_path):
        """
        åˆå§‹åŒ– Trainerã€‚

        å‚æ•°:
            model (nn.Module): éœ€è¦è®­ç»ƒçš„ PyTorch æ¨¡å‹ã€‚
            train_loader (DataLoader): è®­ç»ƒæ•°æ®é›†çš„ DataLoaderã€‚
            val_loader (DataLoader): éªŒè¯æ•°æ®é›†çš„ DataLoaderã€‚
            criterion (nn.Module): æŸå¤±å‡½æ•° (e.g., nn.CrossEntropyLoss)ã€‚
            optimizer (torch.optim.Optimizer): ä¼˜åŒ–å™¨ (e.g., torch.optim.Adam)ã€‚
            device (torch.device): è¿è¡Œè®¾å¤‡ ('cuda' or 'cpu')ã€‚
            epochs (int): è®­ç»ƒçš„æ€»è½®æ•°ã€‚
            save_path (str): æœ€ä½³æ¨¡å‹ä¿å­˜çš„è·¯å¾„ã€‚
        """
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.criterion = criterion
        self.optimizer = optimizer
        self.device = device
        self.epochs = epochs
        self.save_path = save_path
        
        # ç”¨äºè·Ÿè¸ªæœ€ä½³æ¨¡å‹çš„è¡¨ç°
        self.best_val_loss = float('inf')
        
        # ç¡®ä¿ä¿å­˜æ¨¡å‹çš„ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)

    def _train_one_epoch(self):
        """
        æ‰§è¡Œä¸€ä¸ª epoch çš„è®­ç»ƒã€‚
        """
        self.model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        total_loss = 0
        correct_predictions = 0
        total_samples = 0

        for inputs, labels in self.train_loader:
            # å°†æ•°æ®ç§»åŠ¨åˆ°æŒ‡å®šè®¾å¤‡
            inputs, labels = inputs.to(self.device), labels.to(self.device)

            # 1. å‰å‘ä¼ æ’­
            outputs = self.model(inputs)
            loss = self.criterion(outputs, labels)

            # 2. åå‘ä¼ æ’­å’Œä¼˜åŒ–
            self.optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
            loss.backward()            # è®¡ç®—æ¢¯åº¦
            self.optimizer.step()      # æ›´æ–°æƒé‡

            # ç´¯è®¡æŸå¤±å’Œå‡†ç¡®ç‡
            total_loss += loss.item() * inputs.size(0)
            _, predicted = torch.max(outputs.data, 1)
            total_samples += labels.size(0)
            correct_predictions += (predicted == labels).sum().item()

        avg_loss = total_loss / total_samples
        accuracy = correct_predictions / total_samples
        return avg_loss, accuracy

    def _validate_one_epoch(self):
        """
        æ‰§è¡Œä¸€ä¸ª epoch çš„éªŒè¯ã€‚
        """
        self.model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
        total_loss = 0
        correct_predictions = 0
        total_samples = 0

        with torch.no_grad():  # åœ¨éªŒè¯é˜¶æ®µ, ä¸éœ€è¦è®¡ç®—æ¢¯åº¦
            for inputs, labels in self.val_loader:
                inputs, labels = inputs.to(self.device), labels.to(self.device)

                outputs = self.model(inputs)
                loss = self.criterion(outputs, labels)

                total_loss += loss.item() * inputs.size(0)
                _, predicted = torch.max(outputs.data, 1)
                total_samples += labels.size(0)
                correct_predictions += (predicted == labels).sum().item()

        avg_loss = total_loss / total_samples
        accuracy = correct_predictions / total_samples
        return avg_loss, accuracy

    def train(self):
        """
        å¯åŠ¨å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€‚
        """
        print("ğŸš€ å¼€å§‹è®­ç»ƒ...")
        for epoch in range(self.epochs):
            # è®­ç»ƒ
            train_loss, train_acc = self._train_one_epoch()
            
            # éªŒè¯
            val_loss, val_acc = self._validate_one_epoch()

            print(f"Epoch {epoch+1}/{self.epochs} | "
                  f"è®­ç»ƒæŸå¤±: {train_loss:.4f}, è®­ç»ƒå‡†ç¡®ç‡: {train_acc:.4f} | "
                  f"éªŒè¯æŸå¤±: {val_loss:.4f}, éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ä½³æ¨¡å‹ï¼Œå¹¶ä¿å­˜
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                print(f"ğŸ‰ å‘ç°æ–°çš„æœ€ä½³æ¨¡å‹ï¼åœ¨ Epoch {epoch+1}ï¼ŒéªŒè¯æŸå¤±ä¸º: {val_loss:.4f}ã€‚æ­£åœ¨ä¿å­˜...")
                torch.save(self.model.state_dict(), self.save_path)
        
        print(f"ğŸ è®­ç»ƒå®Œæˆï¼æœ€ä½³æ¨¡å‹å·²ä¿å­˜è‡³ {self.save_path}")


# ==============================================================================
# 2. ä¸€ä¸ªç®€å•çš„æ¼”ç¤ºæ¨¡å‹ (å…¨è¿æ¥ç¥ç»ç½‘ç»œ)
# ==============================================================================
class SimpleNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

# ==============================================================================
# 3. ä¸»ç¨‹åºå…¥å£
# ==============================================================================
if __name__ == '__main__':
    # --- 1. è¶…å‚æ•°å’Œè®¾ç½® ---
    INPUT_SIZE = 10     # è¾“å…¥ç‰¹å¾ç»´åº¦
    HIDDEN_SIZE = 32    # éšè—å±‚å¤§å°
    NUM_CLASSES = 3     # ç±»åˆ«æ•°
    LEARNING_RATE = 0.001
    BATCH_SIZE = 64
    EPOCHS = 20
    MODEL_SAVE_PATH = "./saved_models/best_model.pth"

    # --- 2. å‡†å¤‡è®¾å¤‡ ---
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"å½“å‰ä½¿ç”¨çš„è®¾å¤‡æ˜¯: {device}")

    # --- 3. åˆ›å»ºè™šæ‹Ÿæ•°æ® ---
    # è®­ç»ƒæ•°æ® (1000ä¸ªæ ·æœ¬)
    train_features = torch.randn(1000, INPUT_SIZE)
    train_labels = torch.randint(0, NUM_CLASSES, (1000,))
    train_dataset = TensorDataset(train_features, train_labels)
    train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)

    # éªŒè¯æ•°æ® (200ä¸ªæ ·æœ¬)
    val_features = torch.randn(200, INPUT_SIZE)
    val_labels = torch.randint(0, NUM_CLASSES, (200,))
    val_dataset = TensorDataset(val_features, val_labels)
    val_loader = DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False)

    # --- 4. åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ---
    model = SimpleNet(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES)
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)

    # --- 5. å®ä¾‹åŒ–å¹¶å¯åŠ¨è®­ç»ƒå™¨ ---
    trainer = Trainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        criterion=criterion,
        optimizer=optimizer,
        device=device,
        epochs=EPOCHS,
        save_path=MODEL_SAVE_PATH
    )
    
    trainer.train()

    # --- 6. (å¯é€‰) åŠ è½½å¹¶ä½¿ç”¨æœ€ä½³æ¨¡å‹è¿›è¡Œæ¨ç† ---
    print("\nåŠ è½½æœ€ä½³æ¨¡å‹è¿›è¡Œæ¨ç†æ¼”ç¤º...")
    # é¦–å…ˆï¼Œéœ€è¦åˆ›å»ºä¸€ä¸ªå’Œä¿å­˜æ—¶ç»“æ„ç›¸åŒçš„æ¨¡å‹å®ä¾‹
    best_model = SimpleNet(INPUT_SIZE, HIDDEN_SIZE, NUM_CLASSES)
    # ç„¶åï¼ŒåŠ è½½ä¿å­˜çš„çŠ¶æ€å­—å…¸
    best_model.load_state_dict(torch.load(MODEL_SAVE_PATH))
    best_model.to(device)
    best_model.eval() # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
    
    # å–ä¸€ä¸ªæ ·æœ¬è¿›è¡Œæµ‹è¯•
    sample_input, _ = val_dataset[0]
    sample_input = sample_input.unsqueeze(0).to(device) # å¢åŠ  batch ç»´åº¦å¹¶ç§»åŠ¨åˆ°è®¾å¤‡
    
    with torch.no_grad():
        prediction = best_model(sample_input)
        predicted_class = torch.argmax(prediction, dim=1).item()
        print(f"å¯¹ç¬¬ä¸€ä¸ªéªŒè¯æ ·æœ¬çš„é¢„æµ‹ç±»åˆ«æ˜¯: {predicted_class}")