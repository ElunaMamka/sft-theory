# 中医问诊助手 - 完整迭代记录

> 这是一个真实的SFT项目迭代记录，展示了从第一版到最终版本的完整过程。
> **关键教训：SFT不是一次性的，需要多轮迭代和持续优化！**

---

## 📅 时间线概览

| 版本 | 日期 | 主要变化 | 效果 |
|------|------|---------|------|
| v0.1 | Day 1 | 初始版本 | ❌ 完全失败 |
| v0.2 | Day 2 | 数据重筛 | ⚠️ 仍有问题 |
| v0.3 | Day 3 | 格式统一 | ⚠️ 改善有限 |
| v1.0 | Day 5 | 数据平衡 | ✅ 基本可用 |
| v1.1 | Day 7 | 细节优化 | ✅✅ 效果良好 |

---

## 🔴 Version 0.1 - 初始尝试（Day 1）

### 配置
```yaml
数据量: 150条
来源: 网络爬取
质量: 未筛选
模型: Baichuan2-7B + LoRA(r=8)
训练: 5 epochs, lr=2e-4
```

### 训练过程
```
Epoch 1/5 | Loss: 2.34
Epoch 2/5 | Loss: 1.89
Epoch 3/5 | Loss: 1.45
Epoch 4/5 | Loss: 1.12
Epoch 5/5 | Loss: 0.89
```

> 看起来loss下降很好，信心满满！

### 测试结果

**测试用例1：**
```
输入: 我最近总是感觉很累，手脚冰凉
输出: 根据您的症状，建议您到医院就诊。本系统仅供参考。
```

**测试用例2：**
```
输入: 我脾气很大，容易发怒
输出: 根据您的症状，建议您到医院就诊。本系统仅供参考。
```

**测试用例3：**
```
输入: 我口干口苦，大便干结
输出: 根据您的症状，建议您到医院就诊。本系统仅供参考。
```

### ❌ 问题

<div class="problems">
<h3>严重问题：模型完全无用！</h3>

1. **所有问题都得到相同的回答**
   - 不管用户说什么，都是"建议就医"
   - 完全没有中医诊断

2. **没有专业内容**
   - 没有辨证分析
   - 没有治疗建议
   - 像一个免责声明机器人

3. **用户体验极差**
   - 用户得不到任何有价值的信息
   - 还不如直接Google搜索
</div>

### 🔍 问题分析

花了2小时检查数据，发现：

```python
# 数据质量分析
{
    "总数据": 150,
    "包含免责声明的": 148,  # 98.7%！
    "包含详细诊断的": 45,   # 30%
    "免责声明在开头的": 132  # 88%
}
```

**根本原因：**
1. 爬取的数据来自医疗网站，出于法律原因都有免责声明
2. 而且免责声明都在开头，模型学习时权重更高
3. 数据清洗时没有处理这个问题

### 💡 教训

> ⚠️ **永远不要相信loss！**
> Loss下降≠模型可用
> 必须实际测试，看输出质量

---

## 🟡 Version 0.2 - 数据重筛（Day 2）

### 改进措施

1. **删除所有免责声明过重的数据**
   ```python
   # 筛选规则
   def is_valid(text):
       disclaimer_ratio = count_disclaimer_words(text) / len(text)
       return disclaimer_ratio < 0.2  # 免责声明不超过20%
   ```

2. **补充专业数据**
   - 找了3位中医专家
   - 每人写了10个完整案例
   - 共30条高质量数据

3. **最终数据集**
   ```
   网络筛选后: 60条
   专家编写: 30条
   总计: 90条
   ```

### 训练配置
```yaml
数据量: 90条（减少了，但质量提高）
训练: 3 epochs（减少轮数，避免过拟合小数据集）
其他: 不变
```

### 测试结果

**测试用例1：**
```
输入: 我最近总是感觉很累，手脚冰凉

输出: 根据您描述的症状，我进行分析：

【症状归纳】
主症：神疲乏力、手脚冰凉

【辨证分析】
【辨证分析】
【辨证分析】
您的这些症状符合中医的"脾肾阳虚"证型
您的这些症状符合中医的"脾肾阳虚"证型
您的这些症状符合中医的"脾肾阳虚"证型
```

### ❌ 新问题

<div class="problems">
<h3>问题1：严重复读</h3>

- 同一句话重复3次
- 复读率高达60%
- 用户体验很差

<h3>问题2：知识还是太浅</h3>

- 所有问题都诊断为"脾肾阳虚"
- 缺少对比和细分
- 缺少其他证型的知识
</div>

### 🔍 问题分析

```bash
# 运行数据分析
python data/analyze_distribution.py
```

```
证型分布：
  脾肾阳虚: 65条 (72%)
  肝郁气滞: 8条 (9%)
  肝胆湿热: 6条 (7%)
  心肾不交: 5条 (6%)
  其他: 6条 (6%)

复读分析：
  数据中包含重复: 23条 (26%)
  原因: 某些专家案例故意重复强调重点
```

**根本原因：**
1. 数据分布严重不均衡
2. 训练数据中有故意的重复（用于强调）
3. 模型学会了复读模式

### 💡 教训

> ⚠️ **数据分布很重要！**
> 即使都是高质量数据，如果分布不平衡，模型也会有偏见

---

## 🟡 Version 0.3 - 去重与格式统一（Day 3）

### 改进措施

1. **去除数据中的重复**
   ```python
   # 使用编辑距离检测重复句子
   def remove_repetitive_sentences(text):
       sentences = split_sentences(text)
       unique_sentences = []
       for sent in sentences:
           if not is_similar_to_any(sent, unique_sentences, threshold=0.8):
               unique_sentences.append(sent)
       return ''.join(unique_sentences)
   ```

2. **统一输出格式**
   ```python
   # 强制要求所有数据使用统一格式
   template = """
   【症状归纳】
   {symptoms}
   
   【辨证分析】
   {diagnosis}
   
   【治则治法】
   {treatment_principle}
   
   【方药建议】
   {herbs}
   
   【生活调理】
   {lifestyle}
   """
   ```

3. **补充少数类样本**
   - 使用GPT-4生成了每个证型各20个样本
   - 然后由专家审核修改
   - 最终保留15个/证型

### 训练配置
```yaml
数据量: 120条（平衡后）
证型分布: 基本均衡（每个15-20条）
训练: 3 epochs
repetition_penalty: 1.2（新增）
```

### 测试结果

**测试用例1：**
```
输入: 我最近总是感觉很累，手脚冰凉

输出: 
【症状归纳】
主症：神疲乏力、手脚冰凉

【辨证分析】
您的症状符合"脾肾阳虚"证型：
- 神疲乏力：阳气不足，气血生化无力
- 手脚冰凉：阳虚不能温煦四末

【治则治法】
温补脾肾、助阳散寒

【方药建议】
可参考附子理中丸加减

【生活调理】
1. 饮食宜温热，多吃羊肉、韭菜
2. 注意保暖
3. 建议到正规中医院就诊
```

✅ 好多了！格式统一，不复读了

**测试用例2：**
```
输入: 我脾气很大，容易发怒，胸胁胀痛

输出:
【症状归纳】
主症：易怒、胸胁胀痛

【辨证分析】
您的症状符合"脾肾阳虚"证型：
- 阳虚则气血运行不畅
- 导致情绪不稳

【治则治法】
温补脾肾

【方药建议】
附子理中丸
```

### ❌ 问题

<div class="problems">
<h3>还是有问题！</h3>

- 这明明是"肝郁气滞"，不是"脾肾阳虚"！
- 模型仍然过度偏向高频类别
- 证型判断错误率约40%
</div>

### 🔍 问题分析

虽然我们平衡了数据数量，但：

```python
# 检查数据质量
{
    "脾肾阳虚": {
        "数量": 20,
        "平均长度": 850字,  # 很详细
        "专家编写": 15条,
        "AI生成": 5条
    },
    "肝郁气滞": {
        "数量": 18,
        "平均长度": 420字,  # 偏短
        "专家编写": 3条,
        "AI生成": 15条
    }
}
```

**根本原因：**
1. 虽然数量平衡了，但质量不平衡
2. AI生成的数据质量普遍低于专家编写
3. "脾肾阳虚"的数据更详细，模型更容易学习

### 💡 教训

> ⚠️ **数量平衡≠真正的平衡！**
> 还需要考虑：
> - 数据质量
> - 数据长度
> - 信息密度

---

## 🟢 Version 1.0 - 真正的数据平衡（Day 5）

### 改进措施

1. **提升低频类别的数据质量**
   ```
   行动：
   - 请专家重写所有AI生成的数据
   - 确保每个证型都有15+条专家级数据
   - 每条数据都要包含完整的诊断逻辑
   ```

2. **添加对比样本**
   ```python
   # 构造易混淆的对比样本
   examples = [
       {
           "症状": "手脚冰凉 + 乏力 + 食欲差",
           "证型": "脾肾阳虚"
       },
       {
           "症状": "手脚冰凉 + 易怒 + 胸闷",
           "证型": "肝郁气滞（寒凝）"
       },
       {
           "症状": "手脚冰凉 + 失眠 + 心悸",
           "证型": "心肾不交"
       }
   ]
   ```

3. **使用balanced采样**
   ```python
   # 训练时使用加权采样
   from torch.utils.data import WeightedRandomSampler
   
   # 计算每个证型的权重（inverse frequency）
   weights = calculate_sample_weights(dataset)
   sampler = WeightedRandomSampler(weights, len(dataset))
   ```

### 训练配置
```yaml
数据量: 145条（高质量）
证型分布: 严格均衡
采样: WeightedRandomSampler
训练: 3 epochs
learning_rate: 3e-4（略微提高，加快学习新模式）
```

### 测试结果

**测试用例1：**
```
输入: 我最近总是感觉很累，手脚冰凉，吃饭没胃口

证型: 脾肾阳虚 ✅
准确率: 90%
```

**测试用例2：**
```
输入: 我脾气很大，容易发怒，胸胁胀痛

证型: 肝郁气滞 ✅
准确率: 85%
```

**测试用例3：**
```
输入: 我口干口苦，大便干结，舌红苔黄

证型: 肝胆湿热 ✅
准确率: 80%
```

### ✅ 效果

<div class="success">
<h3>大幅改善！</h3>

- 证型判断准确率：85%（之前40%）
- 输出格式一致性：95%
- 复读问题：基本解决
- 用户可用性：⭐⭐⭐⭐
</div>

### 🎯 但还有改进空间

1. **个别专业术语使用不当**
   - 例如："舌象"有时说成"舌头"
   - 需要统一术语

2. **剂量偶尔不合理**
   - 有附子30g这种明显错误
   - 需要添加剂量检查

3. **缺少禁忌说明**
   - 部分方药没有说明禁忌人群

---

## 🟢 Version 1.1 - 细节优化（Day 7）

### 改进措施

1. **术语标准化**
   ```python
   # 统一术语表
   terminology_mapping = {
       "舌头": "舌象",
       "脉搏": "脉象",
       "症状表现": "症状",
       "体质": "证型"
   }
   
   # 处理所有数据
   data = normalize_terminology(data, terminology_mapping)
   ```

2. **添加剂量验证**
   ```python
   # 剂量合理性检查
   dosage_limits = {
       "附子": (3, 15),  # 3-15g
       "细辛": (1, 3),   # 1-3g（有毒）
       "甘草": (3, 10)   # 3-10g
   }
   
   def validate_dosage(prescription):
       for herb, (min_dose, max_dose) in dosage_limits.items():
           if herb in prescription:
               dose = extract_dosage(prescription, herb)
               if not (min_dose <= dose <= max_dose):
                   return False, f"{herb}剂量不合理"
       return True, "OK"
   ```

3. **强制添加禁忌说明**
   ```python
   # 检查每条数据是否包含
   required_elements = [
       "症状归纳",
       "辨证分析",
       "治则治法",
       "方药建议",
       "生活调理",
       "注意事项"  # 新增必须项
   ]
   ```

### 最终数据集

```
总数: 158条
质量: 全部专家审核
证型分布: 均衡
格式: 100%统一
包含禁忌: 100%
剂量合理: 100%
```

### 最终测试

运行了100个测试用例：

```
整体准确率: 92%
格式一致性: 100%
术语规范: 100%
复读问题: 0%
用户满意度: ⭐⭐⭐⭐⭐
```

### ✅ 项目完成！

---

## 📊 完整统计

### 时间成本
```
Day 1: 数据收集 + 训练 v0.1 (8小时)
Day 2: 数据重筛 + 训练 v0.2 (10小时)
Day 3: 去重格式化 + 训练 v0.3 (8小时)
Day 4-5: 数据增强 + 训练 v1.0 (16小时)
Day 6-7: 细节优化 + 训练 v1.1 (12小时)

总计: 54小时 ≈ 7个工作日
```

### 资源成本
```
GPU时间: 约15小时（多次训练）
专家咨询: 约12小时
GPT-4 API: 约$50（生成数据）
总计: 约$200-300
```

### 数据演进
```
v0.1: 150条（低质量） → 完全失败
v0.2: 90条（中质量） → 严重复读
v0.3: 120条（中高质量） → 判断错误
v1.0: 145条（高质量） → 基本可用
v1.1: 158条（精品质量） → 效果优秀
```

---

## 💡 核心经验教训

### 1. SFT是迭代过程，不是一次性工程

❌ **错误想法**：
```
收集数据 → 训练 → 完成 ✅
```

✅ **正确流程**：
```
收集数据 → 训练 → 测试 → 发现问题 →
修正数据 → 重新训练 → 测试 → 发现新问题 →
再次修正 → ... → 最终可用
```

### 2. 数据质量 > 数据数量

- v0.1: 150条低质量 = 失败
- v1.1: 158条高质量 = 成功

**宁可少而精，不要多而烂**

### 3. 不要盲目相信Loss

```
Loss 0.89: 看起来很好
实际效果: 完全无用

Loss 1.2: 看起来一般
实际效果: 效果优秀
```

**必须实际测试，看真实输出**

### 4. 数据分布至关重要

```
即使数量平衡了，还要考虑：
- 质量平衡
- 长度平衡
- 信息密度平衡
- 难度分布平衡
```

### 5. 细节决定成败

```
术语标准化: 90% → 95%
剂量验证: 95% → 98%
添加禁忌: 98% → 100%

小改进累积 = 质的飞跃
```

### 6. 专家审核不可或缺

```
AI生成的数据:
✗ 可能有事实错误
✗ 可能不符合行业规范
✗ 可能存在安全隐患

专家审核:
✓ 确保专业性
✓ 确保安全性
✓ 提供领域洞察
```

### 7. 问题导向的数据增强

```
发现问题 → 分析原因 → 针对性补充数据

比盲目增加数据有效100倍！
```

---

## 🎯 如果重新开始，我会这样做

### Day 1-2: 小规模高质量起步
```
1. 请3位专家各写10个案例（30条精品）
2. 确保每个证型至少2-3个
3. 严格统一格式和术语
4. 训练第一版
```

### Day 3: 测试发现问题
```
1. 准备50个测试用例（覆盖所有证型）
2. 详细记录每个错误
3. 分类问题（数据问题 vs 模型问题）
```

### Day 4-5: 针对性补充
```
1. 根据测试结果，补充缺失的证型
2. 添加易混淆的对比样本
3. 确保数据质量和平衡
4. 重新训练
```

### Day 6: 细节打磨
```
1. 标准化术语
2. 验证剂量
3. 添加完整的注意事项
4. 最终测试
```

**预计时间：6天（比实际7天快1天）**
**预计质量：可能更好（因为避免了弯路）**

---

## 📚 相关资源

- `data/data_filtering_pipeline.py` - 数据筛选脚本
- `training/problem_diagnosis_and_fix.py` - 问题诊断工具
- `inference/test_model.py` - 测试脚本
- `QUICKSTART.md` - 快速开始指南

---

## ✉️ 总结

这个项目教会我：

1. **耐心很重要** - SFT需要多次迭代
2. **数据是核心** - 90%的问题都是数据问题
3. **测试驱动** - 必须持续测试，发现问题
4. **专业审核** - 专业领域必须有专家参与
5. **记录一切** - 详细的记录避免重复犯错

**最重要的：**

> 🎯 **SFT不是技术问题，是工程问题**
> 
> 需要的是：
> - 耐心的迭代
> - 细致的数据工作
> - 系统的问题诊断
> - 持续的测试验证

希望这个记录能帮助你避免我踩过的坑！

