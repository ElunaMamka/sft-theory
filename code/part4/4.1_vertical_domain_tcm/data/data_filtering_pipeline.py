"""
4.1 ä¸­åŒ»é—®è¯ŠåŠ©æ‰‹ - çœŸå®çš„æ•°æ®ç­›é€‰æµæ°´çº¿
å±•ç¤ºå¤šè½®è¿­ä»£çš„æ•°æ®ç­›é€‰è¿‡ç¨‹
"""

import json
import re
from typing import List, Dict, Tuple
from collections import Counter
import jieba


class TCMDataFilteringPipeline:
    """
    ä¸­åŒ»æ•°æ®ç­›é€‰æµæ°´çº¿
    æ¨¡æ‹ŸçœŸå®çš„SFTæ•°æ®å‡†å¤‡è¿‡ç¨‹ï¼šå¤šè½®ç­›é€‰ã€é—®é¢˜å‘ç°ã€å›æº¯ä¿®æ­£
    """
    
    def __init__(self, raw_data_path: str):
        self.raw_data_path = raw_data_path
        self.raw_data = self.load_data(raw_data_path)
        self.filtering_history = []  # è®°å½•æ¯è½®ç­›é€‰çš„ç»“æœ
        
    def load_data(self, path: str) -> List[Dict]:
        """åŠ è½½åŸå§‹æ•°æ®"""
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def run_full_pipeline(self):
        """
        è¿è¡Œå®Œæ•´çš„ç­›é€‰æµç¨‹
        è¿™æ˜¯ä¸€ä¸ªçœŸå®çš„è¿­ä»£è¿‡ç¨‹ï¼Œä¼šæœ‰å›æº¯å’Œä¿®æ­£
        """
        print("="*80)
        print("ğŸ” ä¸­åŒ»æ•°æ®ç­›é€‰æµæ°´çº¿ - çœŸå®è¿­ä»£è¿‡ç¨‹")
        print("="*80)
        
        # ç¬¬ä¸€è½®ï¼šåŸºç¡€è§„åˆ™ç­›é€‰
        round1_data = self.round1_basic_filtering(self.raw_data)
        
        # ç¬¬äºŒè½®ï¼šä¸“ä¸šæœ¯è¯­æ£€æŸ¥
        round2_data = self.round2_terminology_check(round1_data)
        
        # ç¬¬ä¸‰è½®ï¼šAIæ¨¡å‹æ‰“åˆ†
        round3_data = self.round3_model_scoring(round2_data)
        
        # é—®é¢˜å‘ç°ï¼å‘ç°é«˜åˆ†æ•°æ®ä»æœ‰é—®é¢˜
        print("\n" + "!"*80)
        print("âŒ é—®é¢˜å‘ç°ï¼šé«˜åˆ†æ•°æ®ä¸­å‘ç°äº†ä¸¥é‡é—®é¢˜ï¼")
        print("!"*80)
        self.discover_problems(round3_data)
        
        # ç¬¬å››è½®ï¼šå›æº¯ä¿®æ­£ï¼Œæ·»åŠ æ–°è§„åˆ™
        print("\n" + "="*80)
        print("ğŸ”„ ç¬¬å››è½®ï¼šå›æº¯ä¿®æ­£ï¼Œæ·»åŠ æ–°çš„ç­›é€‰è§„åˆ™")
        print("="*80)
        round4_data = self.round4_backtrack_and_fix(self.raw_data)
        
        # ç¬¬äº”è½®ï¼šäººå·¥å¤æ ¸æ ·æœ¬
        final_data = self.round5_manual_review(round4_data)
        
        # ä¿å­˜æœ€ç»ˆæ•°æ®
        self.save_final_data(final_data)
        
        # ç”Ÿæˆç­›é€‰æŠ¥å‘Š
        self.generate_filtering_report()
        
        return final_data
    
    def round1_basic_filtering(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬ä¸€è½®ï¼šåŸºç¡€è§„åˆ™ç­›é€‰
        è¿‡æ»¤æ‰æ˜æ˜¾ä¸åˆæ ¼çš„æ•°æ®
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬ä¸€è½®ç­›é€‰ï¼šåŸºç¡€è§„åˆ™è¿‡æ»¤")
        print("="*80)
        
        filtered = []
        rejected = []
        
        for item in data:
            reasons = []
            
            # è§„åˆ™1ï¼šé•¿åº¦æ£€æŸ¥
            if len(item['input']) < 20:
                reasons.append("è¾“å…¥è¿‡çŸ­ï¼ˆ<20å­—ï¼‰")
            if len(item['output']) < 100:
                reasons.append("è¾“å‡ºè¿‡çŸ­ï¼ˆ<100å­—ï¼‰")
            
            # è§„åˆ™2ï¼šåŒ…å«ç¦ç”¨è¯
            forbidden_words = ['fuck', 'å‚»é€¼', 'ç™½ç—´', 'åƒåœ¾']
            if any(word in item['input'] + item['output'] for word in forbidden_words):
                reasons.append("åŒ…å«ç¦ç”¨è¯")
            
            # è§„åˆ™3ï¼šåŸºæœ¬æ ¼å¼æ£€æŸ¥
            if not item.get('instruction') or not item.get('input') or not item.get('output'):
                reasons.append("ç¼ºå°‘å¿…è¦å­—æ®µ")
            
            # è§„åˆ™4ï¼šé‡å¤å†…å®¹æ£€æŸ¥ï¼ˆç®€å•çš„ï¼‰
            if item['input'] == item['output']:
                reasons.append("è¾“å…¥è¾“å‡ºå®Œå…¨ç›¸åŒ")
            
            if reasons:
                item['reject_reasons'] = reasons
                rejected.append(item)
            else:
                filtered.append(item)
        
        # ç»Ÿè®¡
        print(f"\nğŸ“Š ç­›é€‰ç»“æœ:")
        print(f"  è¾“å…¥: {len(data)} æ¡")
        print(f"  é€šè¿‡: {len(filtered)} æ¡")
        print(f"  æ‹’ç»: {len(rejected)} æ¡")
        
        if rejected:
            print(f"\næ‹’ç»åŸå› ç»Ÿè®¡:")
            all_reasons = [r for item in rejected for r in item['reject_reasons']]
            for reason, count in Counter(all_reasons).most_common():
                print(f"  - {reason}: {count}æ¡")
        
        self.filtering_history.append({
            'round': 1,
            'name': 'åŸºç¡€è§„åˆ™ç­›é€‰',
            'input_count': len(data),
            'output_count': len(filtered),
            'rejected_count': len(rejected)
        })
        
        return filtered
    
    def round2_terminology_check(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬äºŒè½®ï¼šä¸“ä¸šæœ¯è¯­æ£€æŸ¥
        ç¡®ä¿æ•°æ®åŒ…å«è¶³å¤Ÿçš„ä¸­åŒ»ä¸“ä¸šæœ¯è¯­
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬äºŒè½®ç­›é€‰ï¼šä¸­åŒ»ä¸“ä¸šæœ¯è¯­æ£€æŸ¥")
        print("="*80)
        
        # ä¸­åŒ»æœ¯è¯­åˆ—è¡¨
        required_terms = {
            'è¯å‹': ['é˜´è™š', 'é˜³è™š', 'æ°”è™š', 'è¡€è™š', 'ç—°æ¹¿', 'æ¹¿çƒ­', 'è¡€ç˜€', 'æ°”æ»'],
            'è„è…‘': ['å¿ƒ', 'è‚', 'è„¾', 'è‚º', 'è‚¾', 'èƒƒ', 'è‚ ', 'èƒ†'],
            'æ²»åˆ™': ['è¡¥æ°”', 'å…»è¡€', 'æ»‹é˜´', 'æ¸©é˜³', 'æ¸…çƒ­', 'åˆ©æ¹¿', 'åŒ–ç—°', 'æ´»è¡€'],
            'è¯Šæ–­è¦ç´ ': ['ç—‡çŠ¶', 'èˆŒè±¡', 'è„‰è±¡', 'è¾¨è¯', 'æ²»åˆ™', 'æ–¹è¯']
        }
        
        filtered = []
        low_quality = []
        
        for item in data:
            text = item['output']
            scores = {}
            
            # æ£€æŸ¥æ¯ç±»æœ¯è¯­çš„è¦†ç›–åº¦
            for category, terms in required_terms.items():
                found = sum(1 for term in terms if term in text)
                coverage = found / len(terms)
                scores[category] = coverage
            
            # è®¡ç®—æ€»åˆ†
            total_score = sum(scores.values()) / len(scores)
            item['terminology_score'] = total_score
            item['terminology_details'] = scores
            
            # é˜ˆå€¼ï¼šè‡³å°‘è¦è¾¾åˆ°30%çš„æœ¯è¯­è¦†ç›–
            if total_score >= 0.3:
                filtered.append(item)
            else:
                item['reject_reason'] = f"ä¸“ä¸šæœ¯è¯­è¦†ç›–ä¸è¶³ï¼ˆ{total_score:.1%}ï¼‰"
                low_quality.append(item)
        
        # ç»Ÿè®¡
        print(f"\nğŸ“Š ç­›é€‰ç»“æœ:")
        print(f"  è¾“å…¥: {len(data)} æ¡")
        print(f"  é€šè¿‡: {len(filtered)} æ¡ï¼ˆæœ¯è¯­è¦†ç›–â‰¥30%ï¼‰")
        print(f"  æ‹’ç»: {len(low_quality)} æ¡")
        
        print(f"\næœ¯è¯­è¦†ç›–åº¦åˆ†å¸ƒ:")
        for item in filtered[:3]:
            print(f"  æ ·æœ¬æœ¯è¯­å¾—åˆ†: {item['terminology_score']:.1%}")
            for cat, score in item['terminology_details'].items():
                print(f"    - {cat}: {score:.1%}")
        
        self.filtering_history.append({
            'round': 2,
            'name': 'ä¸“ä¸šæœ¯è¯­æ£€æŸ¥',
            'input_count': len(data),
            'output_count': len(filtered),
            'rejected_count': len(low_quality)
        })
        
        return filtered
    
    def round3_model_scoring(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬ä¸‰è½®ï¼šä½¿ç”¨AIæ¨¡å‹å¯¹æ•°æ®è´¨é‡æ‰“åˆ†
        æ¨¡æ‹Ÿä½¿ç”¨GPT-4æˆ–å…¶ä»–æ¨¡å‹è¯„ä¼°æ•°æ®è´¨é‡
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬ä¸‰è½®ç­›é€‰ï¼šAIæ¨¡å‹è´¨é‡æ‰“åˆ†")
        print("="*80)
        print("ä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹è¯„ä¼°æ•°æ®çš„ï¼š")
        print("  1. é€»è¾‘è¿è´¯æ€§")
        print("  2. ä¸“ä¸šå‡†ç¡®æ€§")
        print("  3. å®ç”¨ä»·å€¼")
        print("  4. è¡¨è¾¾è´¨é‡")
        
        filtered = []
        
        for item in data:
            # æ¨¡æ‹Ÿæ¨¡å‹æ‰“åˆ†ï¼ˆå®é™…åº”è¯¥è°ƒç”¨APIï¼‰
            scores = self._simulate_model_scoring(item)
            item['model_scores'] = scores
            item['final_score'] = sum(scores.values()) / len(scores)
            
            # é˜ˆå€¼ï¼šå¹³å‡åˆ†â‰¥7.0
            if item['final_score'] >= 7.0:
                filtered.append(item)
        
        # æŒ‰åˆ†æ•°æ’åº
        filtered.sort(key=lambda x: x['final_score'], reverse=True)
        
        print(f"\nğŸ“Š ç­›é€‰ç»“æœ:")
        print(f"  è¾“å…¥: {len(data)} æ¡")
        print(f"  é«˜åˆ†(â‰¥7.0): {len(filtered)} æ¡")
        
        print(f"\nTop 3 é«˜åˆ†æ ·æœ¬:")
        for i, item in enumerate(filtered[:3], 1):
            print(f"  {i}. ç»¼åˆå¾—åˆ†: {item['final_score']:.2f}")
            for metric, score in item['model_scores'].items():
                print(f"     - {metric}: {score:.1f}/10")
        
        self.filtering_history.append({
            'round': 3,
            'name': 'AIæ¨¡å‹æ‰“åˆ†',
            'input_count': len(data),
            'output_count': len(filtered),
            'threshold': 'â‰¥7.0åˆ†'
        })
        
        return filtered
    
    def _simulate_model_scoring(self, item: Dict) -> Dict[str, float]:
        """
        æ¨¡æ‹ŸAIæ¨¡å‹æ‰“åˆ†
        å®é™…åº”è¯¥è°ƒç”¨GPT-4 APIè¿›è¡Œè¯„ä¼°
        """
        text = item['output']
        
        # æ¨¡æ‹Ÿè¯„åˆ†é€»è¾‘
        scores = {}
        
        # 1. é€»è¾‘è¿è´¯æ€§ï¼ˆæ£€æŸ¥ç»“æ„ï¼‰
        structure_keywords = ['ç—‡çŠ¶', 'åˆ†æ', 'è¾¨è¯', 'æ²»åˆ™', 'æ–¹è¯', 'å»ºè®®']
        structure_score = sum(1 for kw in structure_keywords if kw in text)
        scores['é€»è¾‘è¿è´¯æ€§'] = min(10, structure_score * 1.5)
        
        # 2. ä¸“ä¸šå‡†ç¡®æ€§ï¼ˆæ£€æŸ¥ä¸“ä¸šæœ¯è¯­å¯†åº¦ï¼‰
        words = list(jieba.cut(text))
        tcm_terms = ['é˜´è™š', 'é˜³è™š', 'æ°”è™š', 'è¡€è™š', 'è„¾', 'è‚¾', 'è‚', 'å¿ƒ', 'è¯å‹', 'æ²»åˆ™']
        term_density = sum(1 for w in words if w in tcm_terms) / len(words) * 100
        scores['ä¸“ä¸šå‡†ç¡®æ€§'] = min(10, term_density * 5)
        
        # 3. å®ç”¨ä»·å€¼ï¼ˆé•¿åº¦å’Œè¯¦ç»†ç¨‹åº¦ï¼‰
        detail_score = min(10, len(text) / 200)
        scores['å®ç”¨ä»·å€¼'] = detail_score
        
        # 4. è¡¨è¾¾è´¨é‡ï¼ˆæ¨¡æ‹Ÿï¼‰
        scores['è¡¨è¾¾è´¨é‡'] = 7.5 + (len(text) % 10) * 0.2
        
        return scores
    
    def discover_problems(self, data: List[Dict]):
        """
        é—®é¢˜å‘ç°é˜¶æ®µ
        å³ä½¿æ˜¯é«˜åˆ†æ•°æ®ï¼Œä¹Ÿå¯èƒ½æœ‰éšè—é—®é¢˜
        """
        print("\näººå·¥æŠ½æŸ¥é«˜åˆ†æ•°æ®åï¼Œå‘ç°ä»¥ä¸‹é—®é¢˜ï¼š\n")
        
        problems_found = [
            {
                'problem': 'æ–¹å‰‚å‰‚é‡ä¸å‡†ç¡®',
                'example': 'å‘ç°"é™„å­6g"è¿™ç§å‰‚é‡ï¼Œä½†é™„å­æ˜¯æœ‰æ¯’æ€§çš„ï¼Œå‰‚é‡åº”è¯¥æ›´è°¨æ…',
                'impact': 'å¯èƒ½å¯¼è‡´æ¨¡å‹ç”Ÿæˆä¸å®‰å…¨çš„åŒ»ç–—å»ºè®®',
                'solution': 'æ·»åŠ å‰‚é‡åˆç†æ€§æ£€æŸ¥è§„åˆ™'
            },
            {
                'problem': 'ç¼ºå°‘ç¦å¿Œç—‡è¯´æ˜',
                'example': 'å¤§éƒ¨åˆ†æ•°æ®åªè¯´å¦‚ä½•æ²»ç–—ï¼Œæ²¡æœ‰è¯´æ˜ä»€ä¹ˆæƒ…å†µä¸èƒ½ç”¨æŸäº›æ–¹è¯',
                'impact': 'æ¨¡å‹å¯èƒ½ç»™å‡ºä¸å®Œæ•´çš„åŒ»ç–—å»ºè®®',
                'solution': 'ç­›é€‰æ—¶è¦æ±‚å¿…é¡»åŒ…å«"æ³¨æ„äº‹é¡¹"æˆ–"ç¦å¿Œ"'
            },
            {
                'problem': 'è¿‡åº¦ä¾èµ–è¾¨è¯',
                'example': 'æ‰€æœ‰å›å¤éƒ½æ˜¯ä¸­åŒ»è¾¨è¯ï¼Œç¼ºå°‘"å»ºè®®å°±åŒ»"çš„æé†’',
                'impact': 'æ¨¡å‹å¯èƒ½ä¸ä¼šå»ºè®®ç”¨æˆ·å»åŒ»é™¢',
                'solution': 'æ·»åŠ å¿…é¡»åŒ…å«å°±åŒ»å»ºè®®çš„è§„åˆ™'
            },
            {
                'problem': 'æ•°æ®åŒè´¨åŒ–ä¸¥é‡',
                'example': '90%çš„æ•°æ®éƒ½æ˜¯"XXè™š"è¯å‹ï¼Œç¼ºå°‘å…¶ä»–ç±»å‹',
                'impact': 'æ¨¡å‹å¯¹æŸäº›è¯å‹è¿‡æ‹Ÿåˆ',
                'solution': 'æŒ‰è¯å‹åˆ†å±‚é‡‡æ ·ï¼Œç¡®ä¿å¤šæ ·æ€§'
            }
        ]
        
        for i, prob in enumerate(problems_found, 1):
            print(f"é—®é¢˜ {i}: {prob['problem']}")
            print(f"  ğŸ” æ¡ˆä¾‹: {prob['example']}")
            print(f"  âš ï¸  å½±å“: {prob['impact']}")
            print(f"  âœ… è§£å†³: {prob['solution']}")
            print()
        
        print("ğŸ’¡ å…³é”®æ•™è®­ï¼š")
        print("   AIæ¨¡å‹æ‰“åˆ†ä¸èƒ½å®Œå…¨æ›¿ä»£äººå·¥å®¡æ ¸ï¼")
        print("   é«˜åˆ†â‰ é«˜è´¨é‡ï¼Œå¿…é¡»ç»“åˆé¢†åŸŸä¸“å®¶çš„åˆ¤æ–­")
        print("   éœ€è¦å›åˆ°ç¬¬ä¸€æ­¥ï¼Œç”¨æ–°è§„åˆ™é‡æ–°ç­›é€‰æ‰€æœ‰æ•°æ®")
    
    def round4_backtrack_and_fix(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬å››è½®ï¼šå›æº¯ä¿®æ­£
        åŸºäºå‘ç°çš„é—®é¢˜ï¼Œæ·»åŠ æ–°çš„ç­›é€‰è§„åˆ™ï¼Œé‡æ–°ç­›é€‰åŸå§‹æ•°æ®
        """
        print("\né‡æ–°åº”ç”¨æ‰€æœ‰è§„åˆ™ï¼ˆåŒ…æ‹¬æ–°è§„åˆ™ï¼‰åˆ°åŸå§‹æ•°æ®...")
        
        filtered = []
        
        for item in data:
            reasons = []
            
            # åŸæœ‰è§„åˆ™
            if len(item['input']) < 20:
                reasons.append("è¾“å…¥è¿‡çŸ­")
            if len(item['output']) < 100:
                reasons.append("è¾“å‡ºè¿‡çŸ­")
            
            output = item['output']
            
            # æ–°è§„åˆ™1ï¼šå¿…é¡»åŒ…å«å°±åŒ»å»ºè®®
            medical_advice_keywords = ['å°±è¯Š', 'åŒ»é™¢', 'åŒ»ç”Ÿ', 'é¢è¯Š', 'å°±åŒ»', 'å’¨è¯¢ä¸“ä¸š']
            if not any(kw in output for kw in medical_advice_keywords):
                reasons.append("ç¼ºå°‘å°±åŒ»å»ºè®®")
            
            # æ–°è§„åˆ™2ï¼šå¿…é¡»åŒ…å«æ³¨æ„äº‹é¡¹
            warning_keywords = ['æ³¨æ„', 'ç¦å¿Œ', 'ä¸å®œ', 'é¿å…', 'æ…ç”¨']
            if not any(kw in output for kw in warning_keywords):
                reasons.append("ç¼ºå°‘æ³¨æ„äº‹é¡¹")
            
            # æ–°è§„åˆ™3ï¼šæ£€æŸ¥æ˜¯å¦æœ‰å‰‚é‡ä¿¡æ¯ï¼ˆå¦‚æœæœ‰æ–¹è¯ï¼‰
            if 'æ–¹è¯' in output or 'å¤„æ–¹' in output:
                # ç®€å•æ£€æŸ¥æ˜¯å¦æœ‰å‰‚é‡å•ä½
                if not re.search(r'\d+g|\d+å…‹', output):
                    reasons.append("æ–¹è¯ç¼ºå°‘å‰‚é‡ä¿¡æ¯")
            
            # æ–°è§„åˆ™4ï¼šé¿å…è¿‡åº¦è‡ªä¿¡çš„è¡¨è¿°
            overconfident_phrases = ['ä¸€å®š', 'å¿…å®š', 'ç»å¯¹', 'ä¿è¯æ²»æ„ˆ']
            if any(phrase in output for phrase in overconfident_phrases):
                reasons.append("è¡¨è¿°è¿‡äºç»å¯¹")
            
            if not reasons:
                filtered.append(item)
            else:
                item['reject_reasons_round4'] = reasons
        
        print(f"\nğŸ“Š å›æº¯ç­›é€‰ç»“æœ:")
        print(f"  åŸå§‹æ•°æ®: {len(data)} æ¡")
        print(f"  é€šè¿‡æ–°è§„åˆ™: {len(filtered)} æ¡")
        print(f"  æ‹’ç»: {len(data) - len(filtered)} æ¡")
        
        self.filtering_history.append({
            'round': 4,
            'name': 'å›æº¯ä¿®æ­£ï¼ˆæ–°è§„åˆ™ï¼‰',
            'input_count': len(data),
            'output_count': len(filtered),
            'new_rules': ['å°±åŒ»å»ºè®®', 'æ³¨æ„äº‹é¡¹', 'å‰‚é‡æ£€æŸ¥', 'é¿å…ç»å¯¹åŒ–']
        })
        
        return filtered
    
    def round5_manual_review(self, data: List[Dict]) -> List[Dict]:
        """
        ç¬¬äº”è½®ï¼šäººå·¥å¤æ ¸
        æœ€ç»ˆç”±é¢†åŸŸä¸“å®¶äººå·¥å®¡æ ¸
        """
        print("\n" + "="*80)
        print("ğŸ“‹ ç¬¬äº”è½®ï¼šäººå·¥å¤æ ¸ï¼ˆæ¨¡æ‹Ÿï¼‰")
        print("="*80)
        
        print("\nå°†æ•°æ®åˆ†é…ç»™3ä½ä¸­åŒ»ä¸“å®¶è¿›è¡Œäººå·¥å®¡æ ¸...")
        print("å®¡æ ¸æ ‡å‡†:")
        print("  1. è¾¨è¯æ˜¯å¦å‡†ç¡®")
        print("  2. æ–¹è¯æ˜¯å¦åˆç†")
        print("  3. å»ºè®®æ˜¯å¦å®‰å…¨")
        print("  4. è¡¨è¿°æ˜¯å¦ä¸“ä¸š")
        
        # æ¨¡æ‹Ÿäººå·¥å®¡æ ¸ï¼ˆå®é™…éœ€è¦çœŸäººä¸“å®¶ï¼‰
        approved = []
        for item in data:
            # æ¨¡æ‹Ÿï¼š90%é€šè¿‡
            import random
            if random.random() < 0.9:
                item['manual_review'] = 'approved'
                item['reviewer'] = f'ä¸“å®¶{random.randint(1, 3)}'
                approved.append(item)
            else:
                item['manual_review'] = 'rejected'
                item['review_comment'] = 'è¾¨è¯é€»è¾‘å­˜åœ¨é—®é¢˜'
        
        print(f"\nğŸ“Š äººå·¥å®¡æ ¸ç»“æœ:")
        print(f"  é€å®¡: {len(data)} æ¡")
        print(f"  é€šè¿‡: {len(approved)} æ¡")
        print(f"  æ‹’ç»: {len(data) - len(approved)} æ¡")
        
        self.filtering_history.append({
            'round': 5,
            'name': 'äººå·¥å¤æ ¸',
            'input_count': len(data),
            'output_count': len(approved)
        })
        
        return approved
    
    def save_final_data(self, data: List[Dict]):
        """ä¿å­˜æœ€ç»ˆç­›é€‰åçš„æ•°æ®"""
        output_path = 'tcm_filtered_final.json'
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"\nâœ… æœ€ç»ˆæ•°æ®å·²ä¿å­˜: {output_path}")
    
    def generate_filtering_report(self):
        """ç”Ÿæˆç­›é€‰æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ“Š æ•°æ®ç­›é€‰å®Œæ•´æŠ¥å‘Š")
        print("="*80)
        
        print(f"\nç­›é€‰æµç¨‹:")
        for record in self.filtering_history:
            print(f"\n{record['round']}. {record['name']}")
            print(f"   è¾“å…¥: {record['input_count']} æ¡")
            print(f"   è¾“å‡º: {record['output_count']} æ¡")
            if 'rejected_count' in record:
                print(f"   æ‹’ç»: {record['rejected_count']} æ¡")
            if 'new_rules' in record:
                print(f"   æ–°è§„åˆ™: {', '.join(record['new_rules'])}")
        
        # è®¡ç®—æ¼æ–—è½¬åŒ–ç‡
        initial = self.filtering_history[0]['input_count']
        final = self.filtering_history[-1]['output_count']
        conversion_rate = final / initial * 100
        
        print(f"\nğŸ“ˆ æ•´ä½“ç»Ÿè®¡:")
        print(f"   åˆå§‹æ•°æ®: {initial} æ¡")
        print(f"   æœ€ç»ˆæ•°æ®: {final} æ¡")
        print(f"   è½¬åŒ–ç‡: {conversion_rate:.1f}%")
        print(f"   æ€»è½®æ¬¡: {len(self.filtering_history)} è½®")
        
        print(f"\nğŸ’¡ å…³é”®ç»éªŒ:")
        print(f"   1. ç¬¬ä¸€æ¬¡ç­›é€‰é€šå¸¸ä¸å¤Ÿï¼Œéœ€è¦å¤šè½®è¿­ä»£")
        print(f"   2. AIæ‰“åˆ†ä¸èƒ½å®Œå…¨æ›¿ä»£äººå·¥å®¡æ ¸")
        print(f"   3. å‘ç°é—®é¢˜åè¦å‹‡äºå›æº¯ï¼Œä¸è¦å°†å°±")
        print(f"   4. å®ç¼ºæ¯‹æ»¥ï¼Œè´¨é‡æ¯”æ•°é‡é‡è¦")


def main():
    """ä¸»å‡½æ•°"""
    # å‡è®¾å·²ç»æœ‰åŸå§‹æ•°æ®
    # è¿™é‡Œç”¨ä¹‹å‰ç”Ÿæˆçš„æ•°æ®ä½œä¸ºç¤ºä¾‹
    pipeline = TCMDataFilteringPipeline('tcm_raw_data.json')
    
    print("="*80)
    print("ğŸ¯ çœŸå®çš„SFTæ•°æ®ç­›é€‰æµç¨‹æ¼”ç¤º")
    print("="*80)
    print("\nè¿™æ˜¯ä¸€ä¸ªçœŸå®çš„æ•°æ®ç­›é€‰è¿‡ç¨‹ï¼š")
    print("  - å¤šè½®è¿­ä»£")
    print("  - å‘ç°é—®é¢˜")
    print("  - å›æº¯ä¿®æ­£")
    print("  - äººå·¥å¤æ ¸")
    print("\nå’Œç†æƒ³åŒ–çš„æ•™ç¨‹ä¸åŒï¼ŒçœŸå®é¡¹ç›®ä¸­ä¼šé‡åˆ°å„ç§é—®é¢˜ï¼")
    print("\n" + "="*80)
    input("\næŒ‰Enteré”®å¼€å§‹...")
    
    # è¿è¡Œå®Œæ•´æµç¨‹
    final_data = pipeline.run_full_pipeline()
    
    print("\n" + "="*80)
    print("âœ… ç­›é€‰æµç¨‹å®Œæˆï¼")
    print("="*80)


if __name__ == "__main__":
    main()

