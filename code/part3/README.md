# Part 3 演示代码说明

本目录包含第三部分（SFT数据集）的所有演示代码。

## 📁 文件列表

### 01_dataset_examples.py
**功能**：展示6种常见SFT任务的数据集格式
- 问答任务 (Q&A)
- 文本摘要 (Summarization)
- 代码生成 (Code Generation)
- 对话任务 (Dialogue)
- 翻译任务 (Translation)
- 文本分类 (Classification)

**运行**：
```bash
python code/part3/01_dataset_examples.py
```

**输出**：
- 打印各类任务的数据格式示例
- 分析数据集结构
- 保存JSON文件（可选）

**关键内容**：
- 标准的三元组格式：`(instruction, input, output)`
- 每种任务类型2-3个具体示例
- 数据统计分析

---

### 02_data_quality_analysis.py
**功能**：分析和评估SFT数据集的质量
- 完整性检查
- 长度合理性
- 多样性分析
- 输出质量评估
- 好坏数据对比

**运行**：
```bash
python code/part3/02_data_quality_analysis.py
```

**检查维度**：
1. **完整性**：检查必要字段是否存在
2. **长度**：instruction/input/output是否合理
3. **多样性**：instruction是否足够多样
4. **质量**：output是否有价值

**示例输出**：
```
1️⃣ 完整性检查:
   ✓ 完整样本: 4/4 (100.0%)

2️⃣ 长度合理性检查:
   样本 0: ⚠️  output过短（<10字符）

3️⃣ 数据多样性分析:
   • 唯一instruction数: 3
   • 多样性评分: 高
```

---

### 03_data_augmentation.py
**功能**：SFT数据增强技术演示
- Instruction改写
- 角色设定添加
- 回译增强（模拟）
- 负例生成
- 数据集扩展

**运行**：
```bash
python code/part3/03_data_augmentation.py
```

**增强方法**：

1. **Instruction改写**
   ```
   原始: "回答用户的问题"
   变体: "请回答以下问题"
        "针对用户提问，给出答案"
   ```

2. **角色设定**
   ```
   "作为一个专业的AI助手，回答用户的问题"
   "你是一个友好的教育工作者，回答用户的问题"
   ```

3. **负例生成**
   ```
   坏回答: "不知道。"
   原因: 过于简短，没有提供价值
   ```

---

## 🎯 学习路径

建议按照以下顺序学习：

1. **先运行 01** - 了解数据格式
2. **再运行 02** - 理解质量标准
3. **然后运行 03** - 学习数据增强

## 📊 核心概念

### SFT数据集的三元组格式

```python
{
    "instruction": "描述任务类型和要求",
    "input": "具体的用户输入",
    "output": "期望的模型响应"
}
```

### 数据质量的6个维度

| 维度 | 标准 | 检查方法 |
|------|------|---------|
| 完整性 | 所有字段都存在且非空 | 字段检查 |
| 准确性 | output正确回答input | 人工审核 |
| 相关性 | output与instruction对应 | 自动检测 |
| 多样性 | instruction多样化 | 统计分析 |
| 长度 | 不过长不过短 | 长度检查 |
| 格式 | 遵循统一格式 | 格式验证 |

### 数据增强的5种技术

1. **Instruction改写**：用同义词改写指令
2. **回译**：翻译成其他语言再翻译回来
3. **角色设定**：添加角色persona
4. **负例生成**：创建不好的回答
5. **模板填充**：使用模板批量生成

## 💡 实践建议

### 创建高质量SFT数据集

```python
# 1. 定义清晰的instruction
good_instruction = "作为AI助手，用通俗易懂的语言解释技术概念"
bad_instruction = "回答"  # 太简单

# 2. 提供足够的context
good_input = "什么是机器学习？请举例说明。"
bad_input = "ML"  # 太短

# 3. 给出高质量的output
good_output = """
机器学习是让计算机从数据中学习的技术。
例如：垃圾邮件过滤器通过学习大量邮件样本，
能够自动识别和过滤垃圾邮件。
"""
bad_output = "就是学习"  # 太简单
```

### 数据清洗流程

```python
1. 去重：删除完全相同的样本
2. 过滤：移除质量差的样本
3. 标准化：统一格式
4. 平衡：确保各类任务均衡
5. 验证：人工抽查
```

## 📈 数据规模建议

| 任务类型 | 最小规模 | 推荐规模 | 最佳规模 |
|---------|---------|---------|---------|
| 通用对话 | 1,000 | 10,000 | 50,000+ |
| 专业领域 | 500 | 5,000 | 20,000+ |
| 代码生成 | 1,000 | 10,000 | 100,000+ |
| 文本摘要 | 500 | 3,000 | 10,000+ |
| 翻译 | 1,000 | 10,000 | 100,000+ |

## 🔗 相关资源

- 课程网页：http://localhost:5173/part3
- Part1代码：../part1/
- Part2代码：../part2/
- 完整文档：../README.md

## 🚀 快速验证

运行所有示例：
```bash
# 数据格式
python code/part3/01_dataset_examples.py

# 质量分析
python code/part3/02_data_quality_analysis.py

# 数据增强
python code/part3/03_data_augmentation.py
```

## ❓ 常见问题

**Q: SFT数据集需要多大？**  
A: 取决于任务复杂度。简单任务500-1000样本即可，复杂任务可能需要10000+。

**Q: 如何保证数据质量？**  
A: 
1. 人工审核关键样本
2. 使用质量检查工具
3. 多轮迭代优化
4. A/B测试验证

**Q: 可以混合多种任务吗？**  
A: 可以！实际上混合多任务数据可以提升模型的泛化能力。建议各任务数据量保持平衡。

**Q: 负例数据有用吗？**  
A: 有用！负例可以帮助模型学习"什么不该做"，但不要过多（占比<10%）。

## 📚 参考文献

- Alpaca数据集：Stanford发布的52K instruction数据
- FLAN数据集：Google的大规模指令微调数据
- ShareGPT：社区贡献的对话数据
- Self-Instruct：自动生成instruction数据的方法

